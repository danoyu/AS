{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travail réalisé par : KHELOUI Gaya\n",
    "## 3525803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des bibliothèques necessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as dt\n",
    "import numpy as np\n",
    "import random\n",
    "import pylab as plb\n",
    "from scipy.special import logit \n",
    "import  matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Function\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## une fois le dataset telecharge, mettre download=False !\n",
    "## Pour le test, train = False\n",
    "## transform permet de faire un preprocessing des donnees (ici ?)\n",
    "batch_size=64\n",
    "nb_digits=10\n",
    "test_loader = dt.DataLoader(datasets.MNIST('../data', train=False, download=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])), batch_size=batch_size, shuffle=True) \n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('../data', train=True, download=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])), batch_size=batch_size, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(ypred,yreal) :\n",
    "    ypred_ = transform(ypred)\n",
    "    yreal_ = transform(yreal)\n",
    "    return sum((torch.eq(ypred_,yreal_)))\n",
    "\n",
    "def transform(ypredict) :\n",
    "    y_return = torch.FloatTensor(ypredict.size()[0])\n",
    "    y_return.zero_()\n",
    "    for i in range(ypredict.size()[0]) :\n",
    "        valeur, indice_max = torch.max(ypredict[i],0)\n",
    "        y_return[i] = indice_max.data[0]\n",
    "    return y_return\n",
    "\n",
    "def calcul_accuracy(loader,modules,batch_size,nb_digits) :\n",
    "    resultat = 0\n",
    "    y_onehot = torch.FloatTensor(batch_size,nb_digits)\n",
    "    for i,(data,target) in enumerate(loader):\n",
    "        if( i < len(loader) - 1) :\n",
    "            y_onehot = torch.FloatTensor(batch_size,nb_digits)\n",
    "            y_onehot.zero_()\n",
    "            y_onehot.scatter_(1, target.view(-1,1), 1)\n",
    "            y_onehot = Variable(y_onehot,requires_grad=False) \n",
    "\n",
    "            data = Variable(data.view(-1 , 28*28))\n",
    "            \n",
    "            ypredict = modules(data) \n",
    "            acc = accuracy(ypredict,y_onehot)\n",
    "            resultat += acc\n",
    "    return resultat / (len(loader) * batch_size * 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe du modele liniaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear_Model_tanh(torch.nn.Module):\n",
    "    def __init__(self , X ,Y) :\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.modele = torch.nn.Linear(X,Y)\n",
    "        \n",
    "        \n",
    "    def forward(self , x):\n",
    "        pred = torch.tanh(self.modele(x))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe du modèle de transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Transform_Model_sigm(torch.nn.Module):\n",
    "    def __init__(self , X ,Y) :\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.modele = torch.nn.Linear(X,Y)\n",
    "        \n",
    "        \n",
    "    def forward(self , x):\n",
    "        return (torch.sigmoid(self.modele(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe représentant une couche HighWay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Couche_HighWay(torch.nn.Module):\n",
    "    def __init__(self , X ,Y) :\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.trans_mod = Transform_Model_sigm(X,Y)\n",
    "        self.lin_mod = Linear_Model_tanh(X,Y)\n",
    "        \n",
    "    def forward(self,x) :\n",
    "        pred = self.lin_mod(x)\n",
    "        mask1 = self.trans_mod(x)\n",
    "        one = Variable(torch.FloatTensor(np.ones((mask1.size()[0],mask1.size()[1]))))\n",
    "        pred_grad = pred.mul(mask1)\n",
    "        mask2 = one.sub(mask1)\n",
    "        sign_gard = x.mul(mask2)\n",
    "        pred = pred_grad.add(sign_gard)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe Représentant La partie HighWay du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HightWay_network(torch.nn.Module):\n",
    "    def __init__(self , X ,Y,nb_couches) :\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.liste_modules = torch.nn.Sequential()\n",
    "        self.nb_couches = nb_couches\n",
    "        for i in range (nb_couches) :\n",
    "            self.liste_modules.add_module(''+str(i),Couche_HighWay(X,Y))\n",
    "                \n",
    "                \n",
    "    def forward(self , x):\n",
    "        data_pred = self.liste_modules(x)\n",
    "        return data_pred    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expérimentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profondeur = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HighWay NetWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration : ', 0, ' MiniBatch : ', 0, ' Erreur en train : ', 63.10878372192383)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 200, ' Erreur en train : ', 18.55070686340332)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 400, ' Erreur en train : ', 11.562779426574707)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 600, ' Erreur en train : ', 11.95739459991455)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 800, ' Erreur en train : ', 6.686069011688232)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 0, ' Erreur en train : ', 4.616051197052002)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 200, ' Erreur en train : ', 4.49773645401001)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 400, ' Erreur en train : ', 6.485945224761963)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 600, ' Erreur en train : ', 3.323836326599121)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 800, ' Erreur en train : ', 4.332510471343994)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 0, ' Erreur en train : ', 3.3705668449401855)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 200, ' Erreur en train : ', 2.993568181991577)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 400, ' Erreur en train : ', 1.7707430124282837)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 600, ' Erreur en train : ', 1.295325517654419)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 800, ' Erreur en train : ', 1.9444701671600342)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 0, ' Erreur en train : ', 1.268802285194397)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 200, ' Erreur en train : ', 0.6266524791717529)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 400, ' Erreur en train : ', 0.463957279920578)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 600, ' Erreur en train : ', 0.8000455498695374)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 800, ' Erreur en train : ', 0.8233045339584351)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 0, ' Erreur en train : ', 0.46326351165771484)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 200, ' Erreur en train : ', 0.7964418530464172)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 400, ' Erreur en train : ', 2.31400203704834)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 600, ' Erreur en train : ', 1.0310865640640259)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 800, ' Erreur en train : ', 1.4726935625076294)\n"
     ]
    }
   ],
   "source": [
    "taille_image  = 28*28\n",
    "nb_digits = 10\n",
    "dim_highWay_network = 200\n",
    "modele = torch.nn.Sequential(Linear_Model_tanh(taille_image,dim_highWay_network),HightWay_network(dim_highWay_network,dim_highWay_network,5),\n",
    "                            Linear_Model_tanh(dim_highWay_network ,nb_digits))  \n",
    "l = torch.nn.MSELoss(size_average=False)\n",
    "step = 0.005\n",
    "tab_err = []\n",
    "tab_acc = []\n",
    "tab_acc_test = []\n",
    "\n",
    "nb_iter = 10\n",
    "\n",
    "y_onehot = torch.FloatTensor(batch_size,nb_digits)\n",
    "for iteration in range(nb_iter):\n",
    "    for i,(data,target) in enumerate(train_loader):\n",
    "        if(i < len(train_loader) -1 ) :\n",
    "            y_onehot = torch.FloatTensor(batch_size,nb_digits)\n",
    "            y_onehot.zero_()\n",
    "            y_onehot.scatter_(1, target.view(-1,1), 1)\n",
    "            y_onehot = Variable(y_onehot,requires_grad=False) \n",
    "            data = Variable(data.view(-1 , taille_image))\n",
    "            y_pred = (modele(data))\n",
    "            erreur  = l(y_pred , y_onehot)\n",
    "            modele.zero_grad()\n",
    "            erreur.backward()\n",
    "            for param in modele.parameters():\n",
    "                param.data -= step * param.grad.data\n",
    "            if iteration % 2 == 0 and i % 200 == 0:\n",
    "                tab_err.append(erreur.data[0])\n",
    "                print (\"Iteration : \",iteration,\" MiniBatch : \",i,\" Erreur en train : \",erreur.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau de neuronne Classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration : ', 0, ' MiniBatch : ', 0, ' Erreur en train : ', 0.10723201185464859)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 200, ' Erreur en train : ', 0.09255336225032806)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 400, ' Erreur en train : ', 0.09122177958488464)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 600, ' Erreur en train : ', 0.08888693153858185)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 800, ' Erreur en train : ', 0.08755185455083847)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 0, ' Erreur en train : ', 0.08337413519620895)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 200, ' Erreur en train : ', 0.08233673125505447)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 400, ' Erreur en train : ', 0.07941962778568268)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 600, ' Erreur en train : ', 0.07938293367624283)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 800, ' Erreur en train : ', 0.07825444638729095)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 0, ' Erreur en train : ', 0.07318016141653061)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 200, ' Erreur en train : ', 0.07429700344800949)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 400, ' Erreur en train : ', 0.07023362815380096)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 600, ' Erreur en train : ', 0.07129300385713577)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 800, ' Erreur en train : ', 0.06766311079263687)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 0, ' Erreur en train : ', 0.06373036652803421)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 200, ' Erreur en train : ', 0.0618634894490242)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 400, ' Erreur en train : ', 0.060044728219509125)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 600, ' Erreur en train : ', 0.061840277165174484)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 800, ' Erreur en train : ', 0.06097627431154251)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 0, ' Erreur en train : ', 0.05652391165494919)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 200, ' Erreur en train : ', 0.05981556326150894)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 400, ' Erreur en train : ', 0.061137180775403976)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 600, ' Erreur en train : ', 0.05298257991671562)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 800, ' Erreur en train : ', 0.054224126040935516)\n"
     ]
    }
   ],
   "source": [
    "taille_image  = 28*28\n",
    "profondeur = 5\n",
    "nb_digits = 10\n",
    "output = 200\n",
    "modele1 = torch.nn.Sequential(Linear_Model_tanh(taille_image,output))  \n",
    "for i in range (profondeur) :\n",
    "    modele1.add_module(''+str(i+1),Linear_Model_tanh(output,output))\n",
    "modele1.add_module(''+str(i+2),Linear_Model_tanh(output,nb_digits))\n",
    "\n",
    "nb_iter = 10\n",
    "l = torch.nn.MSELoss()\n",
    "step = 0.005\n",
    "tab_err_clas = []\n",
    "tab_acc_clas = []\n",
    "tab_acc_test_clas = []\n",
    "\n",
    "y_onehot = torch.FloatTensor(batch_size,nb_digits)\n",
    "for iteration in range(nb_iter):\n",
    "    for i,(data,target) in enumerate(train_loader):\n",
    "        if(i < len(train_loader) -1 ) :\n",
    "            y_onehot = torch.FloatTensor(batch_size,nb_digits)\n",
    "            y_onehot.zero_()\n",
    "            y_onehot.scatter_(1, target.view(-1,1), 1)\n",
    "            y_onehot = Variable(y_onehot,requires_grad=False) \n",
    "            data = Variable(data.view(-1 , taille_image))\n",
    "            y_pred = (modele1(data))\n",
    "            erreur  = l(y_pred , y_onehot)\n",
    "            modele1.zero_grad()\n",
    "            erreur.backward()\n",
    "            for param in modele1.parameters():\n",
    "                param.data -= step * param.grad.data\n",
    "            if iteration % 2 == 0 and i % 200 == 0:\n",
    "                tab_err_clas.append(erreur.data[0])\n",
    "                print (\"Iteration : \",iteration,\" MiniBatch : \",i,\" Erreur en train : \",erreur.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\" Courbe de l'erreur en apprentissage selon le nombre d'iterations \\n profondeur = 5 \")\n",
    "plt.xlabel(\"Nombre d'iterations batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "ylim(-10,70)\n",
    "plt.plot(tab_err_clas,color=\"red\", label = \"Classic\")\n",
    "plt.plot(tab_err,color = \"blue\",  label = \"HighWay\")\n",
    "plt.legend(loc = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profondeur = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HighWay NetWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration : ', 0, ' MiniBatch : ', 0, ' Erreur en train : ', 65.0546875)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 200, ' Erreur en train : ', 57.090030670166016)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 400, ' Erreur en train : ', 45.8299674987793)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 600, ' Erreur en train : ', 38.51225662231445)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 800, ' Erreur en train : ', 31.874818801879883)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 0, ' Erreur en train : ', 22.686025619506836)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 200, ' Erreur en train : ', 15.226015090942383)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 400, ' Erreur en train : ', 6.932811260223389)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 600, ' Erreur en train : ', 7.404471397399902)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 800, ' Erreur en train : ', 5.195773124694824)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 0, ' Erreur en train : ', 2.587137460708618)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 200, ' Erreur en train : ', 4.472926616668701)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 400, ' Erreur en train : ', 6.676675796508789)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 600, ' Erreur en train : ', 2.821730613708496)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 800, ' Erreur en train : ', 3.084888219833374)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 0, ' Erreur en train : ', 0.9146603941917419)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 200, ' Erreur en train : ', 2.862755298614502)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 400, ' Erreur en train : ', 0.9324605464935303)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 600, ' Erreur en train : ', 0.41114184260368347)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 800, ' Erreur en train : ', 0.3673047125339508)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 0, ' Erreur en train : ', 1.6955515146255493)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 200, ' Erreur en train : ', 0.36829158663749695)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 400, ' Erreur en train : ', 2.0520877838134766)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 600, ' Erreur en train : ', 2.479404926300049)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 800, ' Erreur en train : ', 0.2929564118385315)\n"
     ]
    }
   ],
   "source": [
    "taille_image  = 28*28\n",
    "nb_digits = 10\n",
    "dim_highWay_network = 200\n",
    "modele = torch.nn.Sequential(Linear_Model_tanh(taille_image,dim_highWay_network),HightWay_network(dim_highWay_network,dim_highWay_network,12),\n",
    "                            Linear_Model_tanh(dim_highWay_network ,nb_digits))  \n",
    "l = torch.nn.MSELoss(size_average=False)\n",
    "step = 0.005\n",
    "tab_err = []\n",
    "tab_acc = []\n",
    "tab_acc_test = []\n",
    "\n",
    "nb_iter = 10\n",
    "\n",
    "y_onehot = torch.FloatTensor(batch_size,nb_digits)\n",
    "for iteration in range(nb_iter):\n",
    "    for i,(data,target) in enumerate(train_loader):\n",
    "        if(i < len(train_loader) -1 ) :\n",
    "            y_onehot = torch.FloatTensor(batch_size,nb_digits)\n",
    "            y_onehot.zero_()\n",
    "            y_onehot.scatter_(1, target.view(-1,1), 1)\n",
    "            y_onehot = Variable(y_onehot,requires_grad=False) \n",
    "            data = Variable(data.view(-1 , taille_image))\n",
    "            y_pred = (modele(data))\n",
    "            erreur  = l(y_pred , y_onehot)\n",
    "            modele.zero_grad()\n",
    "            erreur.backward()\n",
    "            for param in modele.parameters():\n",
    "                param.data -= step * param.grad.data\n",
    "            if iteration % 2 == 0 and i % 200 == 0:\n",
    "                tab_err.append(erreur.data[0])\n",
    "                print (\"Iteration : \",iteration,\" MiniBatch : \",i,\" Erreur en train : \",erreur.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau de neuronne Classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration : ', 0, ' MiniBatch : ', 0, ' Erreur en train : ', 65.90435791015625)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 200, ' Erreur en train : ', 57.62418746948242)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 400, ' Erreur en train : ', 57.81982421875)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 600, ' Erreur en train : ', 57.58229446411133)\n",
      "('Iteration : ', 0, ' MiniBatch : ', 800, ' Erreur en train : ', 57.65434265136719)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 0, ' Erreur en train : ', 47.25616455078125)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 200, ' Erreur en train : ', 43.54288864135742)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 400, ' Erreur en train : ', 36.70328140258789)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 600, ' Erreur en train : ', 37.7913703918457)\n",
      "('Iteration : ', 2, ' MiniBatch : ', 800, ' Erreur en train : ', 34.653526306152344)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 0, ' Erreur en train : ', 33.97379684448242)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 200, ' Erreur en train : ', 31.75240707397461)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 400, ' Erreur en train : ', 32.56196212768555)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 600, ' Erreur en train : ', 31.52112579345703)\n",
      "('Iteration : ', 4, ' MiniBatch : ', 800, ' Erreur en train : ', 28.691638946533203)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 0, ' Erreur en train : ', 17.32944679260254)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 200, ' Erreur en train : ', 26.38018798828125)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 400, ' Erreur en train : ', 28.223642349243164)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 600, ' Erreur en train : ', 22.54084014892578)\n",
      "('Iteration : ', 6, ' MiniBatch : ', 800, ' Erreur en train : ', 21.47300910949707)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 0, ' Erreur en train : ', 16.926416397094727)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 200, ' Erreur en train : ', 18.06202507019043)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 400, ' Erreur en train : ', 17.48361587524414)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 600, ' Erreur en train : ', 15.611087799072266)\n",
      "('Iteration : ', 8, ' MiniBatch : ', 800, ' Erreur en train : ', 15.46068286895752)\n"
     ]
    }
   ],
   "source": [
    "taille_image  = 28*28\n",
    "profondeur = 12\n",
    "nb_digits = 10\n",
    "output = 200\n",
    "modele1 = torch.nn.Sequential(Linear_Model_tanh(taille_image,output))  \n",
    "for i in range (profondeur) :\n",
    "    modele1.add_module(''+str(i+1),Linear_Model_tanh(output,output))\n",
    "modele1.add_module(''+str(i+2),Linear_Model_tanh(output,nb_digits))\n",
    "\n",
    "nb_iter = 10\n",
    "l = torch.nn.MSELoss(size_average=False)\n",
    "step = 0.0005\n",
    "tab_err_clas = []\n",
    "tab_acc_clas = []\n",
    "tab_acc_test_clas = []\n",
    "\n",
    "y_onehot = torch.FloatTensor(batch_size,nb_digits)\n",
    "for iteration in range(nb_iter):\n",
    "    for i,(data,target) in enumerate(train_loader):\n",
    "        if(i < len(train_loader) -1 ) :\n",
    "            y_onehot = torch.FloatTensor(batch_size,nb_digits)\n",
    "            y_onehot.zero_()\n",
    "            y_onehot.scatter_(1, target.view(-1,1), 1)\n",
    "            y_onehot = Variable(y_onehot,requires_grad=False) \n",
    "            data = Variable(data.view(-1 , taille_image))\n",
    "            y_pred = (modele1(data))\n",
    "            erreur  = l(y_pred , y_onehot)\n",
    "            modele1.zero_grad()\n",
    "            erreur.backward()\n",
    "            for param in modele1.parameters():\n",
    "                param.data -= step * param.grad.data\n",
    "            if iteration % 2 == 0 and i % 200 == 0:\n",
    "                tab_err_clas.append(erreur.data[0])\n",
    "                print (\"Iteration : \",iteration,\" MiniBatch : \",i,\" Erreur en train : \",erreur.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\" Courbe de l'erreur en apprentissage selon le nombre d'iterations \\n profondeur = 12 \")\n",
    "plt.xlabel(\"Nombre d'iterations batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(tab_err_clas,color=\"red\", label = \"Classic\")\n",
    "plt.plot(tab_err,color = \"blue\",  label = \"HighWay\")\n",
    "plt.legend(loc = 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
