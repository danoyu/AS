{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AS : Réseaux de neurones récurrents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau de neurone récurrent SeqToSeq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from charDataset import CharDataset, code2char, char2code\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture des données : Tweets de Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"Donald-Tweets.csv\", \"r\") as f:\n",
    "    spamreader = csv.reader(f, delimiter=',')\n",
    "    tweets = []\n",
    "    vocab = set()\n",
    "    for row in spamreader:\n",
    "        text = re.sub(r'[^a-zA-Z0-9_\\s]','',row[2].lower()) \n",
    "        vocab = vocab | set(text)\n",
    "        tweets.append(text+\" \\n\")\n",
    "    tweets = tweets[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u' ': 0,\n",
       " u'!': 1,\n",
       " u'(': 2,\n",
       " u')': 3,\n",
       " u',': 4,\n",
       " u'.': 5,\n",
       " u':': 6,\n",
       " u';': 7,\n",
       " u'?': 8,\n",
       " u'a': 9,\n",
       " u'b': 10,\n",
       " u'c': 11,\n",
       " u'd': 12,\n",
       " u'e': 13,\n",
       " u'f': 14,\n",
       " u'g': 15,\n",
       " u'h': 16,\n",
       " u'i': 17,\n",
       " u'j': 18,\n",
       " u'k': 19,\n",
       " u'l': 20,\n",
       " u'm': 21,\n",
       " u'n': 22,\n",
       " u'o': 23,\n",
       " u'p': 24,\n",
       " u'q': 25,\n",
       " u'r': 26,\n",
       " u's': 27,\n",
       " u't': 28,\n",
       " u'u': 29,\n",
       " u'v': 30,\n",
       " u'w': 31,\n",
       " u'x': 32,\n",
       " u'y': 33,\n",
       " u'z': 34}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = torch.load('vocab.tx')\n",
    "dictVocab = dict(zip(sorted(vocab),range(len(vocab))))\n",
    "dictVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code2char(code,vocab):\n",
    "    vocab_map = dict(zip(vocab.values(),vocab.keys()))\n",
    "    return \"\".join(vocab_map[c] for c in code)\n",
    "\n",
    "def char2code(text,vocab):\n",
    "    data = torch.ByteTensor(len(text))\n",
    "    for i,c in enumerate(text):\n",
    "        data[i]=vocab[c]\n",
    "    return data\n",
    "\n",
    "######################################################################\n",
    "\n",
    "#tensorTweets = [char2code(t,dictVocab) for t in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabSize = 39, dim=100):\n",
    "        super(RNN, self).__init__()\n",
    "        self.whh = nn.Linear(dim,dim)\n",
    "        self.wxh = nn.Linear(vocabSize,dim)\n",
    "        self.why = nn.Linear(dim,vocabSize)\n",
    "        self.vocabSize = vocabSize\n",
    "        self.dim = dim\n",
    "        if torch.cuda.is_available:\n",
    "            self.whh = self.whh.cuda()\n",
    "            self.wxh = self.wxh.cuda()\n",
    "            self.why = self.why.cuda()\n",
    "        \n",
    "    def forward(self, x, test=True, maxlength=140, stopWord=0):\n",
    "        if torch.cuda.is_available:\n",
    "            lH = [Variable(torch.zeros(x.size(0), self.dim).cuda())]\n",
    "        else : \n",
    "            lH = [Variable(torch.zeros(x.size(0), self.dim))]\n",
    "        linput = [x[:,0]]\n",
    "        _, argmax = x[:,0].max(dim=-1)\n",
    "        maxlength = maxlength if test else x.size(1)\n",
    "        preds = [argmax]\n",
    "        predsProbs=[]\n",
    "        size=1\n",
    "        while(size<maxlength and preds[-1].data[0] != stopWord):\n",
    "            h = F.tanh(self.wxh(linput[-1]) + self.whh(lH[-1]))\n",
    "            lH.append(h)\n",
    "            predProba = self.why(h)\n",
    "            predsProbs.append(predProba)\n",
    "            if test :\n",
    "                linput.append(predProba)\n",
    "                preds.append(self.tirage(predProba))\n",
    "            else:\n",
    "                linput.append(x[:,size -1])\n",
    "            size+=1\n",
    "        return torch.cat(predsProbs),torch.cat(preds)\n",
    "     \n",
    "        \n",
    "    def predict(self,x):\n",
    "        _,decoded = self.forward(x).max(dim=1)\n",
    "        return decoded\n",
    "    \n",
    "    def tirage(self, distribution):\n",
    "        distrib = torch.cat([r / r.sum(dim=-1) for r in distribution])\n",
    "        return distrib.multinomial(1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "('prob : ', Variable containing:\n",
      "-5586.7480\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-11174.2148\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-16756.6973\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-22336.8203\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-27916.5625\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-33496.0859\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-39075.5234\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-44655.1133\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-50234.7031\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-55814.1406\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-61394.9492\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-66988.4844\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-72571.5781\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-78154.0625\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-83737.7656\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-89324.2109\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "-94905.7812\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.0049\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.0607\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.1167\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.1726\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.2284\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.2842\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.3400\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.3959\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.4517\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5076\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.5634\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6193\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.6752\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7310\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.7868\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.8426\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "('prob : ', Variable containing:\n",
      "1.00000e+05 *\n",
      " -1.8984\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n",
      "(Variable containing:\n",
      "-3.8438 -3.8789 -3.6961  ...  -3.7029 -3.4646 -3.8456\n",
      "-3.8438 -3.8789 -3.6961  ...  -3.7029 -3.4646 -3.8456\n",
      "-3.8438 -3.8789 -3.6961  ...  -3.7029 -3.4646 -3.8456\n",
      "          ...             ⋱             ...          \n",
      "-3.7611 -3.8593 -3.6976  ...  -3.7635 -3.4872 -3.7347\n",
      "-3.7611 -3.8593 -3.6976  ...  -3.7635 -3.4872 -3.7347\n",
      "-3.7611 -3.8593 -3.6976  ...  -3.7635 -3.4872 -3.7347\n",
      "[torch.FloatTensor of size 1326x39]\n",
      ", Variable containing:\n",
      " 4\n",
      "[torch.LongTensor of size 1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = RNN()\n",
    "l = np.array([char2code(\"aqbr vvdsvf fdjobrejrejmaojbopjreaop br\", dictVocab),char2code(\"rb r\", dictVocab)])\n",
    "\n",
    "def transform_one_hot(digit,n):\n",
    "    y_onehot = torch.FloatTensor(n)\n",
    "    y_onehot.zero_()\n",
    "    y_onehot[digit] = 1\n",
    "    return y_onehot\n",
    "\n",
    "def transform_one_hot_sequence(sequence,n):\n",
    "    seq_onehot = torch.FloatTensor(len(sequence),n)\n",
    "    for i in range(len(sequence)):\n",
    "        seq_onehot[i] = transform_one_hot(sequence[i],n)\n",
    "    return seq_onehot\n",
    "x = transform_one_hot_sequence(l[0], 35)\n",
    "\n",
    "print(x.size(0))\n",
    "print(m(Variable(x), test=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 97368122.388942\n",
      "Loss 323187650.3203125\n"
     ]
    }
   ],
   "source": [
    "tailleBatch = len(tensorTweets)\n",
    "\n",
    "rnn=RNN()\n",
    "epochs=5\n",
    "\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for ep in range(epochs):\n",
    "    sumLoss = 0.0\n",
    "    for it in range(tailleBatch):\n",
    "        idx = np.random.randint(0,tailleBatch)\n",
    "        exemple = tensorTweets[idx]\n",
    "        x_onehot = torch.FloatTensor(1,len(exemple), len(vocab))\n",
    "        x_onehot.zero_()\n",
    "        x_onehot.scatter_(2, exemple.long().view(1,-1,1),1)\n",
    "        \n",
    "        if torch.cuda.is_available:\n",
    "            exemple = exemple.cuda()\n",
    "            x_onehot = x_onehot.cuda()\n",
    "        \n",
    "        probas, preds = rnn(Variable(x_onehot), test=False)\n",
    "        loss = criterion(probas,Variable(exemple[1:].long()))\n",
    "        sumLoss+=loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del x_onehot\n",
    "    print(\"Loss {}\".format(sumLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0390  0.0709 -0.0152  ...  -0.1245  0.1652 -0.1696\n",
      " 0.0447  0.1991  0.1410  ...   0.0473  0.0858 -0.0955\n",
      "-0.1926  0.0717  0.3021  ...  -0.1663  0.2360  0.1336\n",
      "          ...             ⋱             ...          \n",
      "-0.0493  0.1255  0.2868  ...   0.0699  0.2394 -0.0593\n",
      " 0.0447  0.1991  0.1410  ...   0.0473  0.0858 -0.0955\n",
      "-0.1926  0.0717  0.3021  ...  -0.1663  0.2360  0.1336\n",
      "[torch.cuda.FloatTensor of size 15x512 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      "-1.9702  3.9788 -0.1973  ...   0.1168 -3.1222 -1.6446\n",
      "-1.9702  3.9788 -0.1973  ...   0.1168 -3.1222 -1.6446\n",
      "-1.9702  3.9788 -0.1973  ...   0.1168 -3.1222 -1.6446\n",
      "          ...             ⋱             ...          \n",
      "-1.9702  3.9788 -0.1973  ...   0.1168 -3.1222 -1.6446\n",
      "-1.9702  3.9788 -0.1973  ...   0.1168 -3.1222 -1.6446\n",
      "-1.9702  3.9788 -0.1973  ...   0.1168 -3.1222 -1.6446\n",
      "[torch.cuda.FloatTensor of size 15x512 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch at /pytorch/torch/lib/THC/generic/THCTensorMathBlas.cu:243",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-19aa09a3d9a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5308aeea8dd5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, test)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwxh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwxh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[0;32m---> 26\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch at /pytorch/torch/lib/THC/generic/THCTensorMathBlas.cu:243"
     ]
    }
   ],
   "source": [
    "randIdx = np.random.randint(0,len(dataset),15)\n",
    "x_onehot = torch.FloatTensor(15, 10, dataset.vocab_size)\n",
    "mini_batch_x = torch.cat([dataset[i][0].view(1,-1).float() for i in randIdx], dim=0)\n",
    "mini_batch_y = torch.cat([dataset[i][1].view(1,-1).float() for i in randIdx],dim=0)\n",
    "x_onehot.zero_()\n",
    "x_onehot.scatter_(2, mini_batch_x.long().view(15,10,1),1)\n",
    "rnn(Variable(x_onehot.cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 2.5264384746551514, Predicted : re okafofel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-284c2780c588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0msumLoss\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "#rnn = RNN(dim=512)\n",
    "rnn = torch.load(\"rnn.torch\")\n",
    "x_onehot = torch.FloatTensor(10, dataset.vocab_size) \n",
    "topred = torch.FloatTensor(10,35)\n",
    "if torch.cuda.is_available:\n",
    "    x_onehot = x_onehot.cuda()\n",
    "    topred = topred.cuda()\n",
    "#optimizer = torch.optim.SGD(rnn.parameters(), lr=0.003, momentum=0.9)\n",
    "optimizer = torch.load(\"sgd.torch\")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "for ep in range(epochs):\n",
    "    sumLoss = 0.0\n",
    "    for i in range(len(dataset)):\n",
    "        idx = random.randint(0,len(dataset)-1)\n",
    "        optimizer.zero_grad()\n",
    "        data,target = dataset[idx][0]-1, dataset[idx][1]-1\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        x_onehot.zero_()\n",
    "        x_onehot.scatter_(1, data.view(-1,1).long(), 1)\n",
    "        pred = rnn(Variable(x_onehot),test=False)\n",
    "        loss = criterion(pred,Variable(target.long()))\n",
    "        sumLoss+= loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i %100000==0:\n",
    "            randomChar = random.randint(0,topred.size(1)-1)\n",
    "            topred.zero_()\n",
    "            topred[0][randomChar] = 1\n",
    "            p = rnn(Variable(topred),test=True)\n",
    "            _,argmax = p.max(dim=1)\n",
    "            s = decode(argmax.data, dataset.vocab_map)\n",
    "            print(\"Loss : {}, Predicted : {}\".format(sumLoss, dataset.vocab_map[randomChar+1]+s))\n",
    "            torch.save(rnn,\"rnn.torch\")\n",
    "            torch.save(optimizer,\"sgd.torch\")\n",
    "            sumLoss = 0.0\n",
    "    print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
